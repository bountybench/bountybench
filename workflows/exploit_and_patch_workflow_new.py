Can you review the code below? The idea is that we want a way of instantiating workflows for multi agent architectures.

So essentially, a workflow consists of phases. Each phase consists of agents working together. Resources may be used / reused across phases / agents (i.e. resources likely should be at the workflow level). The resource allocation is handled by the resourcemanager, which can also figure out which resources need to be used in the first place. However, some resources may require configs (do they / can we simplify) which may require some resource awareness at the workflow level?

Overall, I want to have the way of defining / interacting with workflows etc. to be cleaner and a better abstraction to make things easier for new people writing workflows. Currently it doesn't feel right and it feels like there are leaky abstractions and bad coding practices. For instance it feels weird to have REQUIRED_PHASES = [ExploitPhase, PatchPhase]; instead, it feels like you should just have phases as objects which you define and then it'll run. They should not have defined indices, this should just be inferred. 

Also, it'd be nice to automagically be able to run a workflow through commandline simply through defining a workflow class (where the arguments are provided as command line arguments, unlike here where we just call main).

Can you discuss various mechanisms of defining the workflow / workflow instantiation examples and the pros and cons of each approach? Maybe draw inspiration from frameworks like Airflow DAGs and Pytorch (and other frameworks that may have similar abstractions that we can learn from). 

Below I'll provide an example instantiation and then the base classes

------- workflow_example_file.py: example instantiation of workflow

import os
from pathlib import Path

from agents.dataclasses.agent_lm_spec import AgentLMConfig
from agents.patch_agent.patch_agent import PatchAgent, PatchAgentConfig
from agents.exploit_agent.exploit_agent import ExploitAgent, ExploitAgentConfig
from agents.executor_agent.prompt import EXPLOIT_AND_PATCH_PROMPT, STOP_TOKEN
from agents.executor_agent.executor_agent import ExecutorAgent, ExecutorAgentConfig
from phases.base_phase import PhaseConfig
from phases.exploit_phase import ExploitPhase
from phases.patch_phase import PatchPhase
from resources.docker_resource import DockerResource, DockerResourceConfig
from resources.kali_env_resource import KaliEnvResource, KaliEnvResourceConfig
from resources.utils import read_exploit_report
from utils.logger import get_main_logger
from workflows.base_workflow import BaseWorkflow

logger = get_main_logger(__name__)

class ExploitAndPatchWorkflow(BaseWorkflow):
    """Workflow for exploiting and patching vulnerabilities"""


    
    REQUIRED_PHASES = [ExploitPhase, PatchPhase]
    # Agents = ExecutorAgent, ExploitAgent, PatchAgent
    # Resource =  KaliEnvResource, DockerResource (InitFilesResource, (maybe SetupFilesResource (2x)) handled in super)
    exploit_files_path = None
    patch_files_path = None

    def __init__(self, task_repo_dir: Path, bounty_number: str, interactive: bool = False):
        workflow_id = "exploit_and_patch_workflow"
        self.interactive = interactive
        super().__init__(task_repo_dir, bounty_number, workflow_id, interactive)     

    def define_resource_configs(self) -> None:
        """Configure resources"""
        super().define_resource_configs()
                
        # Create exploit_files and patch_files dir for KaliEnvResource volumes
        tmp_dir = os.path.join(str(self.task_repo_dir), "tmp")
        self.exploit_files_path = os.path.join(tmp_dir, "exploit_files")
        self.patch_files_path = os.path.join(tmp_dir, "patch_files")

        os.makedirs(self.exploit_files_path, exist_ok=True)
        os.makedirs(self.patch_files_path, exist_ok=True)
        logger.info(f"Created exploit_files directory at: {self.exploit_files_path}")
        logger.info(f"Created patch_files directory at: {self.patch_files_path}")

        kali_env_config = KaliEnvResourceConfig(
            task_repo_dir=self.task_repo_dir,
            bounty_number=self.bounty_number,
            volumes={
                os.path.abspath(tmp_dir): {"bind": "/app", "mode": "rw"},
                os.path.abspath(self.exploit_files_path): {"bind": "/app/exploit_files", "mode": "rw"},
                os.path.abspath(self.patch_files_path): {"bind": "/app/patch_files", "mode": "rw"},
                "/tmp": {"bind": "/tmp", "mode": "rw"}
            }
        )
        self.register_resource("kali_env", KaliEnvResource, kali_env_config)

        docker_config = DockerResourceConfig()
        self.register_resource("docker", DockerResource, docker_config)

    def create_agents(self) -> None:
        """Configure agents"""
        executor_agent_lm_config = AgentLMConfig(
            model="anthropic/claude-3-5-sonnet-20240620",
            max_output_tokens=4096,
            max_input_tokens=4096,
            max_iterations=25,
            max_iterations_stored_in_memory=3,
            use_helm=True
        )

        executor_agent_config = ExecutorAgentConfig(
            id="executor_agent",
            lm_config=executor_agent_lm_config,
            # logger=self.workflow_logger,
            target_host=self.repo_metadata["target_host"]
        )
        self.create_agent(ExecutorAgent, executor_agent_config)
                
        exploit_agent_config = ExploitAgentConfig(
            id="exploit_agent",
            bounty_dir=os.path.join("bounties", f"bounty_{self.bounty_number}")
            )
        self.create_agent(ExploitAgent, exploit_agent_config)

        patch_agent_config = PatchAgentConfig(
            id="patch_agent",
            bounty_dir=os.path.join("bounties", f"bounty_{self.bounty_number}")
            )
        self.create_agent(PatchAgent, patch_agent_config)

    def create_phases(self) -> None:
        # create_phase takes PhaseClass, optional[max_iterations] (or get from args), optional[agents] (or get [any] class)
        self.create_phase(ExploitPhase)
        self.create_phase(PatchPhase, max_iterations=3)

    def get_initial_prompt(self):
        exploit_report = read_exploit_report(self.task_repo_dir, self.bounty_number)
        prompt = EXPLOIT_AND_PATCH_PROMPT.format(
            task_description=exploit_report,
            stop_token=STOP_TOKEN,
            target_host=self.repo_metadata["target_host"],
        )
        return prompt

def main() -> None:
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Run the exploit and patch workflow")
    parser.add_argument("--task_repo_dir", type=str, help="The directory of the task repo")
    parser.add_argument("--bounty_number", type=str, help="The bounty number")
    parser.add_argument("--interactive", action="store_true", help="Run in interactive mode")
    args = parser.parse_args()
    
    # Create logs directory
    logs_dir = Path("logs")
    logs_dir.mkdir(exist_ok=True)
    
    # Run workflow
    workflow = ExploitAndPatchWorkflow(Path(args.task_repo_dir), args.bounty_number, args.interactive)
    workflow.run()

if __name__ == "__main__":
    main()

------- base_workflow.py: base workflow file

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
import os
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Type

from enum import Enum
import logging

# Import your specific modules and classes here
from agents.base_agent import BaseAgent, AgentConfig
from phases.base_phase import BasePhase, PhaseConfig
from responses.base_response import BaseResponse
from resources.base_resource import BaseResource, BaseResourceConfig
from resources.init_files_resource import InitFilesResourceConfig
from resources.init_files_resource import InitFilesResource
from resources.resource_manager import ResourceManager
from resources.setup_resource import SetupResource, SetupResourceConfig
from resources.utils import docker_network_exists, read_bounty_metadata, read_repo_metadata, run_command
from utils.workflow_logger import workflow_logger

# Initialize the module-level logger
logger = logging.getLogger(__name__)

MAX_ITERATIONS = 10

class WorkflowStatus(Enum):
    """Status of workflow execution"""
    INITIALIZED = "initialized"
    INCOMPLETE = "incomplete"
    COMPLETED_SUCCESS = "completed_success"
    COMPLETED_FAILURE = "completed_failure"
    COMPLETED_MAX_ITERATIONS = "completed_max_iterations"


@dataclass
class WorkflowConfig:
    """Configuration for a workflow"""
    id: str
    max_iterations: int
    logs_dir: Path
    task_repo_dir: Path
    bounty_number: int
    initial_prompt: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    phase_configs: List['PhaseConfig'] = field(default_factory=list)  



class BaseWorkflow(ABC):
    """
    Base class for defining workflows that coordinate phases and their agents.
    
    A workflow:
    - Acts as top-level controller for phases
    - Manages workflow-level logging
    - Coordinates phase transitions and data flow between phases
    - Tracks overall workflow state and completion status
    """
    REQUIRED_PHASES: List[Type[BasePhase]] = []

    def __init__(
        self,
        task_repo_dir: Path,
        bounty_number: str,
        workflow_id: Optional[str] = "base_workflow",
        interactive: Optional[bool] = False
    ):
        """Initialize workflow with configuration"""
        self.task_repo_dir = task_repo_dir
        self.bounty_number = str(bounty_number)  # Ensure it's an integer
        self.repo_metadata = read_repo_metadata(str(task_repo_dir))
        self.bounty_metadata = read_bounty_metadata(str(task_repo_dir), str(self.bounty_number))
        
        # Setup workflow config
        config = WorkflowConfig(
            id=workflow_id,
            max_iterations=25,
            logs_dir=Path("logs"),
            task_repo_dir=task_repo_dir,
            bounty_number=self.bounty_number,
            initial_prompt=self.get_initial_prompt(),
            metadata={
                "repo_metadata": self.repo_metadata,
                "bounty_metadata": self.bounty_metadata
            }
        )

        self.config = config
        self.status = WorkflowStatus.INITIALIZED
        self._current_phase_idx = 0
        self._workflow_iteration_count = 0

        self.workflow_logger = workflow_logger
        self.workflow_logger.initialize(
            workflow_name=config.id,
            logs_dir=str(config.logs_dir),
            task_repo_dir=str(config.task_repo_dir),
            bounty_number=str(config.bounty_number)
        )

        # Add workflow metadata
        for key, value in config.metadata.items():
            self.workflow_logger.add_metadata(key, value)

        # Initialize ResourceManager
        self.resource_manager = ResourceManager()

        # Initialize tracking structures
        self.agents: Dict[str, BaseAgent] = {}  # Maps agent_id to agent_instance
        self.phases: List[BasePhase] = []       # List to store phase instances
        self.phase_class_map = {}

        # Initialize additional attributes
        self.vulnerable_files: List[str] = []

        # Setup workflow
        self.setup_init()
        self.define_resource_configs()
        self.create_agents()
        self.create_phases()

        self.validate_registrations()

        self._compute_schedule()

    @abstractmethod
    def get_initial_prompt(self) -> str:
        """Provide the initial prompt for the workflow."""
        pass

    @abstractmethod
    def create_agents(self) -> None:
        """Calls create_agent for all agents required for the workflow."""
        pass

    def validate_registrations(self):
        """
        Validate that all required phases, agents, and resources are properly registered.
        """
        self._validate_required_phases()
        self._validate_required_agents()
        self._validate_required_resources()

    def _validate_required_phases(self):
        """Validate that all required phases are registered."""
        registered_phase_classes = set(self.phase_class_map.values())
        missing_phases = set(self.REQUIRED_PHASES) - registered_phase_classes
        if missing_phases:
            raise ValueError(f"Missing required phases: {', '.join([p.__name__ for p in missing_phases])}")

    def _validate_required_agents(self):
        """Validate that all required agents for each phase are registered."""
        for phase_class in self.REQUIRED_PHASES:
            required_agents = getattr(phase_class, 'REQUIRED_AGENTS', [])
            registered_agents = set(type(agent) for _, agent in self.agents.items())
            missing_agents = set(required_agents) - registered_agents
            if missing_agents:
                raise ValueError(f"Missing required agents for {phase_class.__name__}: {', '.join([a.__name__ for a in missing_agents])}")

    def _validate_required_resources(self):
        """Validate that all required resources for each agent are registered."""
        all_required_resources = set()
        for agent in self.agents.values():
            all_required_resources.update(resource.__name__ for resource in agent.REQUIRED_RESOURCES)
        
        registered_resource_classes = self.resource_manager.get_registered_resource_classes()
        registered_resources = set(resource_class.__name__ for resource_class in registered_resource_classes)
        
        missing_resources = all_required_resources - registered_resources
        if missing_resources:
            raise ValueError(f"Missing required resources: {', '.join(missing_resources)}")
        
    def _compute_schedule(self) -> None:
        """
        Compute the resource usage schedule across all phases.
        Populates the phase_resources and resource_lifecycle dictionaries in ResourceManager.
        """
        phase_classes = [self.phase_class_map[phase_config.phase_name] for phase_config in self.config.phase_configs]
        self.resource_manager.compute_schedule(phase_classes)
        logger.debug("Computed resource schedule for all phases.")

    def setup_phase(self, phase_index: int, initial_response: Optional[BaseResponse] = None) -> None:
        """
        Setup a specific phase by allocating resources, setting up agents, and creating the phase instance.

        Args:
            phase_index (int): The index of the phase to set up.
        """
        try:
            logger.info(f"Setting up phase {phase_index} with initial response {initial_response}")
            
            # Step 1: Setup resources for the phase
            self.setup_phase_resources(phase_index)
            # Step 2: Setup agents for the phase
            self.setup_phase_agents(phase_index)
            
            phase_instance = self.phases[phase_index]
            
            logger.info(f"Phase {phase_index} setup complete: {phase_instance.__class__.__name__}")
            return phase_instance
        
        except Exception as e:
            self.status = WorkflowStatus.INCOMPLETE
            logger.error(f"Failed to set up phase {phase_index}: {e}")
            raise

    def setup_phase_agents(self, phase_index: int) -> None:
        """
        Setup and configure agents for a given phase.

        Args:
            phase_index (int): The index of the phase for which to set up agents.
        """
        try:
            # Retrieve the PhaseConfig for the given index
            phase_config = self.config.phase_configs[phase_index]
            logger.debug(f"Setting up agents for phase {phase_index}: {phase_config.phase_name}")

            # Register resources for each agent
            for agent_id, agent_instance in phase_config.agents:
                agent_instance.register_resources()
                logger.info(f"Registered resources for agent '{agent_id}' in phase {phase_index}")

        except IndexError:
            logger.error(f"No PhaseConfig found for phase index: {phase_index}")
            raise
        except Exception as e:
            logger.error(f"Error setting up agents for phase {phase_index}: {e}")
            raise

    def setup_phase_resources(self, phase_index: int) -> None:
        """
        Setup all required resources for a phase by allocating them through the ResourceManager.

        Args:
            phase_index (int): The index of the phase for which to allocate resources.
        """
        try:
            self.resource_manager.initialize_phase_resources(phase_index)
            logger.info(f"Resources allocated for phase {phase_index}")
        except Exception as e:
            logger.error(f"Error allocating resources for phase {phase_index}: {e}")
            raise

    def takedown_phase_resources(self, phase_index: int) -> None:
        """
        Setup all required resources for a phase by allocating them through the ResourceManager.

        Args:
            phase_index (int): The index of the phase for which to allocate resources.
        """
        try:
            self.resource_manager.deallocate_phase_resources(phase_index)
            logger.info(f"Relevant resources deallocated after phase {phase_index}")
        except Exception as e:
            logger.error(f"Error deallocating resources after phase {phase_index}: {e}")
            raise

    def create_agent(self, agent_class: Type[BaseAgent], agent_config: AgentConfig) -> BaseAgent:
        """
        Creates and registers an agent.

        Args:
            agent_class (Type[BaseAgent]): The class of the agent to instantiate.
            agent_config (AgentConfig): The configuration for the agent.

        Returns:
            BaseAgent: The instantiated agent.
        """
        try:
            # Instantiate the agent
            agent_instance = agent_class(agent_config=agent_config, resource_manager=self.resource_manager)
            
            # Register the agent in the agents dictionary
            self.agents[agent_config.id] = agent_instance
            logger.info(self.agents[agent_config.id])
            setattr(self, agent_config.id, agent_instance)
            
            # Log the creation
            logger.debug(f"Created agent: {agent_config.id} of type {agent_class.__name__}")
            
            return agent_instance
        except Exception as e:
            logger.error(f"Failed to create agent '{agent_config}': {e}")
            raise

    @abstractmethod
    def create_phases(self) -> None:
        pass

    def create_phase(self, phase_class: BasePhase, max_iterations: Optional[int] = None, agents: Optional[List[str]] = None):
        phase_index = len(self.phases)
        try:
            # Create the phase configuration
            phase_config = PhaseConfig(
                phase_idx=phase_index,
                max_iterations=max_iterations if max_iterations else MAX_ITERATIONS,
                agents=agents if agents else self.get_phase_agents(phase_class),
                interactive=self.interactive
            )

            phase_instance = phase_class(phase_config=phase_config)
            self.phases.append(phase_instance)
            logger.debug(f"Created phase: {phase_class.__name__} for Workflow ID: {self.config.id}")
            return phase_instance
        except Exception as e:
            logger.error(f"Failed to create phase at index {phase_index}: {e}")
            raise

    def get_phase_agents(self, phase_class: BasePhase):
        pass

    def _validate_phase_configs(self) -> None:
        """
        Validate phase configurations before execution.
        Ensures that phase indices are sequential starting from 0.
        """
        if not self.config.phase_configs:
            raise ValueError("No phase configurations provided")
            
        # Validate phase indices are sequential starting from 0
        phase_indices = [phase_config.phase_idx for phase_config in self.config.phase_configs]
        expected_indices = list(range(len(phase_indices)))
        if sorted(phase_indices) != expected_indices:
            raise ValueError("Phase indices must be sequential starting from 0")
        
        logger.debug("Phase configurations validated successfully.")

    def setup_init(self) -> None:
        """Setup initial state of the workflow."""
        self.setup_network()
        self.setup_directories()
        self.setup_git_state()
        # self.log_metadata()

    def setup_network(self) -> None:
        """Setup Docker network if it does not exist."""
        network_name = "shared_net"
        if not docker_network_exists(network_name):
            logger.info(f"Creating Docker network: {network_name}")
            run_command(["docker", "network", "create", network_name])
        else:
            logger.debug(f"Docker network '{network_name}' already exists.")

    def setup_git_state(self) -> None:
        """Setup Git state by checking out the vulnerable commit and identifying vulnerable files."""
        vulnerable_commit = self.bounty_metadata.get('vulnerable_commit', 'main')
        codebase_path = os.path.join(str(self.task_repo_dir), "codebase")
        
        logger.info(f"Checking out vulnerable commit: {vulnerable_commit}")
        run_command(["git", "checkout", vulnerable_commit], codebase_path)
        
        for _, value in self.bounty_metadata.get('patch', {}).items():
            relative_path = os.path.relpath(value, start="codebase")
            full_path = os.path.join(str(self.task_repo_dir), value)
            if os.path.exists(full_path):
                self.vulnerable_files.append(relative_path)
                logger.debug(f"Identified vulnerable file: {relative_path}")
        
        logger.info("Checking out main branch.")
        run_command(["git", "checkout", "main"], codebase_path)

    def setup_directories(self) -> None:
        """Setup necessary directories for the workflow."""
        pass

    # @abstractmethod
    # def log_metadata(self) -> None:
    #     """Log workflow metadata."""
    #     pass

    def register_resource(
        self,
        resource_id: str,
        resource_class: Type[BaseResource],
        resource_config: BaseResourceConfig
    ) -> None:
        """
        Registers a resource with the ResourceManager.

        Args:
            resource_id (str): The unique identifier for the resource.
            resource_class (Type[BaseResource]): The class of the resource.
            resource_config (BaseResourceConfig): The configuration for the resource.
        """
        self.resource_manager.register_resource(resource_id, resource_class, resource_config)
        
        registered_resources = set(self.resource_manager.resources)
        logger.debug(f"Registered resource '{resource_id}' with {getattr(resource_class, '__name__', str(resource_class))}.")

    def define_resource_configs(self) -> None:
        """
        Defines and registers all necessary resources for the workflow.
        """
        try:
            # Define resource directories and configurations by retrieving from metadata or providing defaults
            files_dir = self.bounty_metadata.get('files_dir', 'codebase')
            tmp_dir = self.bounty_metadata.get('tmp_dir', 'tmp')
            exploit_files_dir = self.bounty_metadata.get('exploit_files_dir', f'bounties/bounty_{self.bounty_number}/exploit_files')
            vulnerable_commit = self.bounty_metadata.get('vulnerable_commit', 'main')

            # Initialize InitFilesResource
            init_files_config = InitFilesResourceConfig(
                task_repo_dir=self.task_repo_dir,
                files_dir_name=files_dir,
                tmp_dir_name=tmp_dir,
                exploit_files_dir_name=exploit_files_dir,
                vulnerable_commit=vulnerable_commit
            )
            self.register_resource("init_files", InitFilesResource, init_files_config)
            logger.info("Registered 'init_files' resource.")

            # Setup repository environment if needed
            setup_repo_env_script = os.path.join(str(self.task_repo_dir), "setup_repo_env.sh")
            if os.path.exists(setup_repo_env_script):
                repo_env_config = SetupResourceConfig(
                    task_level_setup=False,
                    task_repo_dir=self.task_repo_dir,
                    files_dir=files_dir
                )
                self.register_resource("repo_resource", SetupResource, repo_env_config)
                logger.info("Registered 'repo_resource' for repository environment.")

            else:
                logger.debug("No repository environment setup script found.")

            # Setup target host if specified
            target_host = self.repo_metadata.get("target_host")
            if target_host:
                task_server_config = SetupResourceConfig(
                    task_level_setup=True,
                    task_repo_dir=self.task_repo_dir,
                    files_dir=files_dir,
                    bounty_number=self.bounty_number,
                    server_address=target_host
                )
                self.register_resource("task_server", SetupResource, task_server_config)
                logger.info(f"Registered 'task_server' for target host: {target_host}")
            else:
                logger.debug("No target host specified in repository metadata.")

        except Exception as e:
            logger.error(f"Failed to define resources: {e}")
            raise

    def run_phases(self):
        """
        Generator that executes workflow phases one at a time.
        Yields (phase_response, phase_success) after each phase execution.
        """
        try:
            # self.setup_phases()
            self._validate_phase_configs()
            self.status = WorkflowStatus.INCOMPLETE
            
            prev_response = None
            if hasattr(self.config, "initial_prompt") and self.config.initial_prompt:
                prev_response = BaseResponse(self.config.initial_prompt)

            if hasattr(self.config, "initial_prompt") and self.config.initial_prompt:
                prev_response = BaseResponse(self.config.initial_prompt)

            # Execute phases in sequence
            for phase_idx, phase_config in enumerate(self.config.phase_configs):
                self._current_phase_idx = phase_idx
                
                # Create and run phase
                phase = self.setup_phase(phase_idx, prev_response)
                logger.info(f"Phase {phase.phase_config.phase_name} set up")
                phase_response, phase_success = phase.run_phase()
                
                # Update workflow state
                prev_response = phase_response
                if not phase_success:
                    self.status = WorkflowStatus.COMPLETED_FAILURE
                    yield phase_response, phase_success
                    yield phase_response, phase_success
                    break
                    
                self._workflow_iteration_count += 1
                if self._workflow_iteration_count >= self.config.max_iterations:
                    self._workflow_iteration_count += 1
                if self._workflow_iteration_count >= self.config.max_iterations:
                    self.status = WorkflowStatus.COMPLETED_MAX_ITERATIONS
                    yield phase_response, phase_success
                    yield phase_response, phase_success
                    break
                
                # Yield current phase results
                yield phase_response, phase_success
                self.takedown_phase_resources(phase_idx)
                    
            # If we completed all phases successfully
            if phase_success and phase_idx == len(self.config.phase_configs) - 1:
                self.status = WorkflowStatus.COMPLETED_SUCCESS
                
            # Finalize workflow
            self.workflow_logger.finalize(self.status.value)
            
        except Exception as e:
            self.status = WorkflowStatus.INCOMPLETE
            self.workflow_logger.finalize(self.status.value)
            raise e

    def run(self) -> None:
        """
        Execute the entire workflow by running all phases in sequence.
        This is a convenience method that runs the workflow to completion.
        """
        # Run through all phases
        for _ in self.run_phases():
            continue

    def run(self) -> None:
        """
        Execute the entire workflow by running all phases in sequence.
        This is a convenience method that runs the workflow to completion.
        """
        # Run through all phases
        for _ in self.run_phases():
            continue

    @property
    def current_phase(self) -> Optional[PhaseConfig]:
        """Get current phase configuration"""
        if 0 <= self._current_phase_idx < len(self.config.phase_configs):
            return self.config.phase_configs[self._current_phase_idx]
        return None